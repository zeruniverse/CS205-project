<!DOCTYPE html>
<!-- saved from url=(0028)https://blog.getpelican.com/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<head>
        <title>Parallelized Deepflow</title>
        <link rel="stylesheet" href="main.css" type="text/css">

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="index.html">Parallelized DeepFlow</a></h1>
                <nav><ul>
                      <li class="active"><a href="index.html">Introduction</a></li>
                      <li><a href="design.html">Design</a></li>
                      <li><a href="performance.html">Performance</a></li>
                      <li><a href="applications.html">Applications</a></li>
                      <li><a href="conclusion.html">Conclusion</a></li>
                </ul></nav>
        </header><!-- /#banner -->
        
<section id="content" class="body">
    <h2 class='entry-title'>Project Overview</h2>
    <p><font face="verdana"> Shiyu Huang, Hongxiang Qiu, Zeyu Zhao, Zongren Zou </font></p>
    <p>In this project, we parallelized an algorithm called DeepFlow with multiple techniques (<b>MPI, OpenMP and OpenACC</b>). Since DeepFlow is useful not only on image processing but also on video processing where independent flows can be generated simultaneously, we thus applied <b>MapReduce</b> for the video processing tasks. Our test result shows the parallelized DeepFlow algorithm can run <b>faster on both image tasks and video tasks</b>.</p>

    <p>Below are the links to the required contents (in grading rubric):</p>

    <ul>
            <li>Application design: <a href="design.html#profiling">profiling</a> and <a href="design.html#application-parallel">parallelization design</a></li>
            <li>Problem solution: introduction of the problem (<a href="#opt-flow">optical flow and DeepFlow</a>) and <a href="#need-hpc">need for HPC</a>. Parallelization is not trivial due to serial dependencies and we <a href="design.html#algorithm">changed the algorithm</a></li>
            <li>Implementation approach: <a href="design.html#implementation">Parallelization implementations</a> and <a href="design.html#code-base">corresponding code</a>. Data can be any two consecutive images or videos. See data preparation and sample data <a href="https://github.com/zeruniverse/CS205-project/blob/master/README.md#prepare-data">here</a></li>
            <li>Platform deployment: <a href="performance.html#data-platform">evaluation platform</a>. Guide to deploy on AWS (or other systems): <a href="https://github.com/zeruniverse/CS205-project/blob/master/README.md#generate-flow">GitHub README</a></li>
            <li>Application software: <a href="https://github.com/zeruniverse/CS205-project/tree/master/src">different parallelizations</a> and <a href="https://github.com/zeruniverse/CS205-project/tree/master/application">applications of DeepFlow</a> (<a href="applications.html">application examples</a>)</li>
            <li>Software documentation: <a href="https://github.com/zeruniverse/CS205-project">GitHub README</a>. There're some separate READMEs for specific modules. You can access them via the links in the main README.</li>
            <li>Performance evaluation and discussion: <a href="performance.html#serial">performance of different linear solvers and different parallelizations</a> (also see overhead analysis and optimizations in the <a href="design.html#implementation">implementation</a> section)</li>
            <li>Advanced features: <a href="design.html#rbsor">RBSOR</a> and <a href="applications.html#slowmo-video">application on slow motion video generation</a></li>
    </ul>

    <hr />
    <h2 class='entry-title' id="opt-flow">Optical Flow</h2>
          <p>Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition. It has many important applications in computer vision, including slow motion video generation, object tracking and etc. Starting from the famous Horn-Schunck algorithm (B. K. Horn and B. G. Schunck. Determining optical flow. Proc. SPIE 0281, Techniques and Applications of Image Understanding, 1981.) and Lucas-Kanade algorithm (B. D. Lucas and T. Kanade. An iterative image registration technique with an application to stereo vision. In IJCAI, volume 81, pages 674â€“679, 1981), researchers have conducted decades of pioneering research, achieving great development in this area.</p>

          <p>Below is a visualization of optical flow. The left GIF is two consecutive frames in a video and the right picture is the visualization of the computed optical flow. (source: <a href="https://people.csail.mit.edu/celiu/OpticalFlow/">https://people.csail.mit.edu/celiu/OpticalFlow/</a>)</p>

          <figure style="clear:both">
            <img src="img/optflow.gif" alt="frames" width="330" style='margin-right:5px'>
            <img src="img/optflow.jpg" alt="frames" width="330" style='margin-left:5px'>
          </figure>

          <p>Optical flow algorithm aims at computing pattern of apparent motion of objects. Given two consecutive images, we would like to compute how each pixel moves from the first image to the second image. Imagine there are three-dimensional vectors describing the motion of the objects in 3-D space. Ideally, the optical flow is the 2-D projection of the three-dimensional vectors on the image. In computer vision, we call this projected two-dimensional vector as flow field. There are four important assumptions for optical flow algorithm:</p>

          <ol>
            <li>Brightness constancy: The image grey value of the pixel does not change during the motion.</li>
            <li>Gradient constancy: it is useful to allow some small variations in the brightness because it often appears in natural scenes. So we assume that the gradient of the image grey value does not vary due to the displacement.</li>
            <li>Smoothness: The movement is a smooth movement.</li>
            <li>Small displacement: Between each pair of consecutive images, the corresponding pixels do not move too far.</li>
            <li>Spatial coherence: points move like their neighbors within patches.</li>
          </ol> 
          <p>Most optical flow algorithms develop their ideas on the basis of these assumptions.</p>
    <hr />
    <h2 class='entry-title' id="DeepFlow">DeepFlow</h2>
    <p>There're many algorithms for optical flow estimation, each with its own focus of special optimization in some aspects. One of the state-of-the-art algorithm is the <a href="https://thoth.inrialpes.fr/src/deepflow/">DeepFlow algorithm</a>. This algorithm has its focus on solving large displacement in optical flow estimation. This property makes it ideal for slow motion video applications (in the scenario of generating slow motion videos, the original videos are likely to have large displacement between consecutive frames). Although there're some real-time optical flow estimation algorithms, their accuracy is worse compared to DeepFlow.</p>
    <p>The deep flow algorithm mainly has two steps:</p>
    <h3>DeepMatching</h3>
    <p>The matching algorithm is used to compute the matching of corresponding pixels in consecutive frames. The <a href="http://lear.inrialpes.fr/src/deepmatching/">deep matching algorithm</a> is built upon a multi-stage architecture with about 6 layers (depending on the image size), interleaving convolutions and max-pooling (a structure similar to deep convolutional nets). The matching stage is to prepare for the flow computation stage.</p>

    <p>The deep matching code is already parallelized and we will just use the existing implementation in our project. Therefore we will skip further explanations on this part.</p>
    <h3>DeepFlow</h3>
    <p>Deep flow is a variational refinement method that blends the result from deep matching algorithm into an energy minimization framework. The energy that the algorithm minimizes (equation below) is a weighted sum of data term E<sub>D</sub>,  smoothness term E<sub>s</sub> and matching term E<sub>M</sub>.</p>

          <figure style="clear:both">
            <img src="img/Energy_minimization.png" alt="energy_eq" width="330" style='margin-right:5px'>
          </figure>

    <p>E<sub>D</sub> is a combination of separate penalization of the color and gradient constancy assumptions with a normalization factor.</p>
          <figure style="clear:both">
            <img src="img/Data_term.png" alt="energy_eq" width="330" style='margin-right:5px'>
          </figure>

    <p>E<sub>s</sub> is based on the smoothness assumption. It is a robust penalization of the gradient flow norm.</p>
        <figure style="clear:both">
            <img src="img/Smooth_term.png" alt="energy_eq" width="330" style='margin-right:5px'>
        </figure>

    <p>E<sub>M</sub> penalizes the difference between the flow and the pre-computed matching vector from deep matching.</p>
    <figure style="clear:both">
            <img src="img/Match_term.png" alt="energy_eq" width="330" style='margin-right:5px'>
    </figure>
    where:
    <figure style="clear:both">
            <img src="img/Match_term_component.png" alt="energy_eq" width="330" style='margin-right:5px'>
    </figure>

    <p>Obviously, the energy function is non-convex and non-linear and it contains integrals, so that energy minimization is pretty complicated. Fortunately, energy function with integrals inside can be minimized by solving its Euler-Lagrange equations, which are second-order partial differential equations, and can be easily derived from integrals in energy function. This is called variational approach, and the solutions are actually functions instead of vectors in regular optimization problems, which fits our optical flow problem perfectly. However, the Euler-Lagrange equations are still nonlinear, and to approximate them with linear system so that they are tractable and can be solved with common numerical methods, we first need to apply fixed point iterations and downsampling and then use first order Taylor expansions to finally get our linear approximation. Furthermore, in order to solve the linear system, we still need numerical methods to have both stable and accurate solution. There are numerous numerical methods for linear system. The original implementation uses Successive Over Relaxation (SOR) method to solve the linear system.</p>
    <hr />

    <h2 class='entry-title' id="need-hpc">Need for HPC and Big Data</h2>

    <p>Using DeepFlow (default settings) to calculate the flow of two 1080p images takes 43 seconds. The time cost is expected to increase linearly as the image size increases, which means 11 minutes for two 8K images. In addition, optical flow is often applied to image sequences (i.e. video). For a 25fps 1080p video, if we want to calculate both forward and backward flows, we need to run DeepFlow 50 times per 1 second video length on average and this means <b>processing 1 second video takes around 36 minutes on a single CPU</b>. If we have a 1080p video of 20 minutes in length, generating the flow on a single CPU takes <b>a month</b>. There're significantly faster algorithms like Dense Inverse Search (DIS), but the accuracy is also worse. For some tasks (like slow motion video generation), we may need good accuracy.</p>

    <p>By using HPC techniques, we can reduce the running time for every single flow. By using Big Data techniques, we can generate multiple flows simultaneously. Therefore, with HPC and Big Data, we can significantly reduce the running time of DeepFlow and make it realistic to apply DeepFlow on long videos.</p>

    <hr />

    <h2 class='entry-title' id="challenges">Challenges</h2>
    <ul>
      <li>The DeepFlow algorithm is not easy to understand.</li>
      <li>Most of time is spent on linear system solver. However, the current linear system solver is not parallelizable due to serial dependency.</li>
      <li>For MPI, the message exchange is not trivial.</li>
      <li>It's pretty hard to apply MapReduce in our problem because the code is in C and the data is binary. (So we can't trivially use Hadoop Streaming like in assignment).</li>
      <li>We want to show some applications of DeepFlow on videos so our work is meaningful. This is not always easy (for example there's existing code but it does not use DeepFlow to calculate the optical flow and we have to write some code to let it use DeepFlow).</li>
    </ul>

</section>
<footer id="contentinfo" class="body">
        <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a></p>
</footer><!-- /#contentinfo -->

</body></html>
